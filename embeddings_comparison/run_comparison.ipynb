{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from embeddings_comparison.utils.llm_clients.cached_client import CachedLLMClient\n",
    "from embeddings_comparison.utils.llm_clients.open_ai_client import OPEN_AI_MODEL_NAME, OpenAIClient\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "open_ai_key = os.environ[\"OPEN_AI_KEY\"]\n",
    "\n",
    "openai_client = OpenAIClient(api_key=open_ai_key, model_name=OPEN_AI_MODEL_NAME.GPT_4O)\n",
    "cached_client = CachedLLMClient(client=openai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data curation\n",
    "Downloading set of articles to be used for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_comparison.utils import wiki_parser\n",
    "from pprint import pprint\n",
    "from embeddings_comparison.utils.storage import ArticleStorage\n",
    "\n",
    "storage = ArticleStorage()\n",
    "\n",
    "raw_pages = wiki_parser.extract_pages_from_file(\"data/Wikipedia-20241111162837.xml\")\n",
    "storage.save_articles(raw_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering\n",
    "\n",
    "Remove sections that don't contain text or are not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_df = storage.load_all()\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Linki zewnętrzne']\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Zobacz też']\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Bibliografia']\n",
    "pages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_comparison.utils.question_generation import BASE_PROMT_PL, generate_question_for_text\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "pbar = tqdm(total=len(pages_df))\n",
    "questions_column = []\n",
    "for _, row in pages_df.iterrows():\n",
    "    pbar.set_description(f\"Generating questions for {row['Section Title']}\")\n",
    "    questions = generate_question_for_text(cached_client, row['Section Content'], BASE_PROMT_PL)\n",
    "    questions_column.append(questions.questions)\n",
    "    pbar.update(1)\n",
    "\n",
    "pages_df['questions'] = questions_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_comparison.utils.embedding_models.caching import CachedEmbeddingModel\n",
    "from embeddings_comparison.utils.embedding_models.hugging_face import HF_EMBEDDING_MODEL_NAME, HFEmbeddingModel\n",
    "from embeddings_comparison.utils.embedding_models.open_ai import OPENAI_EMBEDDING_MODEL_NAME, OpenAIEmbeddingModel\n",
    "from embeddings_comparison.utils.vectordb.vectordb import VectorDB, VectorIndex\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "vector_db = VectorDB()\n",
    "vector_db.add_index(f\"OPENAI_SMALL\", CachedEmbeddingModel(OpenAIEmbeddingModel(api_key=open_ai_key, model=OPENAI_EMBEDDING_MODEL_NAME.TEXT_EMBEDDING_3_SMALL)))\n",
    "vector_db.add_index(f\"OPENAI_LARGE\", CachedEmbeddingModel(OpenAIEmbeddingModel(api_key=open_ai_key, model=OPENAI_EMBEDDING_MODEL_NAME.TEXT_EMBEDDING_3_LARGE)))\n",
    "vector_db.add_index(f\"OPENAI__ADA\", CachedEmbeddingModel(OpenAIEmbeddingModel(api_key=open_ai_key, model=OPENAI_EMBEDDING_MODEL_NAME.TEXT_EMBEDDING_ADA_002)))\n",
    "vector_db.add_index(\"HF_SDADAS\", CachedEmbeddingModel(HFEmbeddingModel(model_name=HF_EMBEDDING_MODEL_NAME.ST_POLISH_PARAPHRASE_FROM_DISTILROBERTA)))\n",
    "\n",
    "for index_name in tqdm(vector_db.list_indices(), desc='Testing Embedding models'):\n",
    "    vector_db.insert_texts(pages_df['Section Content'].values.tolist(), index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "pbar = tqdm(total=len(vector_db.list_indices()))\n",
    "pbar.update(1)\n",
    "for index_name in vector_db.list_indices():\n",
    "    pbar.set_description(f\"Testing {index_name}\")\n",
    "    identified_matches = []\n",
    "    for _, row in tqdm(pages_df.iterrows(), desc=f\"Testing rows for {index_name}\"):\n",
    "        matched_with_answer = 0\n",
    "        for question in row['questions']:\n",
    "            found_text = vector_db.find_text(text=question, top_k=1, index_name=index_name)[0]\n",
    "\n",
    "            if found_text == row['Section Content']:\n",
    "                matched_with_answer += 1\n",
    "        identified_matches.append(matched_with_answer)\n",
    "    pages_df[index_name] = identified_matches\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings-comparison-JqTXriCt-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
