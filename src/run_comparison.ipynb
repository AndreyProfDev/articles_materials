{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from utils.llm_clients.cached_client import CachedLLMClient\n",
    "from utils.llm_clients.cost_monitoring import LLMClientWithCostMonitoring\n",
    "from utils.llm_clients.providers.open_ai_client import OpenAIClient\n",
    "from utils.llm_clients.providers import supported_models\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "open_ai_key = os.environ[\"OPEN_AI_KEY\"]\n",
    "\n",
    "openai_client = OpenAIClient(api_key=open_ai_key, model_info=supported_models.GPT_4O)\n",
    "openai_client = CachedLLMClient(client=openai_client)\n",
    "openai_client = LLMClientWithCostMonitoring(client=openai_client)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logging.info(\"Logging initiated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data curation\n",
    "Downloading set of articles to be used for assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import utils.wiki_parser.wiki_parser as wiki_parser\n",
    "from pprint import pprint\n",
    "from utils.storage import ArticleStorage\n",
    "import os\n",
    "\n",
    "storage = ArticleStorage()\n",
    "\n",
    "for filename in os.listdir(\"data\"):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        print(filename)\n",
    "        raw_pages = wiki_parser.extract_articles_from_file(\"data/\" + filename, output_folder=Path(\"data\"))\n",
    "        storage.save_articles(raw_pages)\n",
    "\n",
    "pages_df = storage.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering\n",
    "\n",
    "Remove sections that don't contain text or are not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_df = storage.load_all()\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Linki zewnętrzne']\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Zobacz też']\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Bibliografia']\n",
    "pages_df = pages_df[pages_df['Section Title'] != 'Przypisy']\n",
    "pages_df = pages_df.drop_duplicates()\n",
    "pages_df = pages_df.reset_index(drop=True)\n",
    "pages_df['Section With Context'] = pages_df['Article Title'] + '\\n' + pages_df['Section Title'] + '\\n' + pages_df['Section Content']\n",
    "pages_df.loc[pages_df['Section Title'] == 'Main', 'Section With Context'] = pages_df['Article Title'] + '\\n' + pages_df['Section Content']\n",
    "pages_df\n",
    "# pages_df.to_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.question_generation import BASE_PROMT_PL, generate_question_for_text\n",
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "pbar = tqdm(total=len(pages_df))\n",
    "questions_column = []\n",
    "\n",
    "promt_tokens_bar = tqdm(desc=\"Promt cost ($): \")\n",
    "completions_tokens_bar = tqdm(desc=\"Completions cost ($):\")\n",
    "\n",
    "for _, row in pages_df.iterrows():\n",
    "    pbar.set_description(f\"Generating questions for {row['Article Title']}/{row['Section Title']}\")\n",
    "    questions = generate_question_for_text(openai_client, row['Section With Context'], BASE_PROMT_PL)\n",
    "    questions_column.append(questions.questions)\n",
    "    pbar.update(1)\n",
    "    # sleep(1)\n",
    "    promt_tokens_bar.update(openai_client.get_total_promt_cost() - promt_tokens_bar.n)\n",
    "    completions_tokens_bar.update(openai_client.get_total_completion_cost() - completions_tokens_bar.n)\n",
    "\n",
    "pages_df['questions'] = questions_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_models.caching import CachedEmbeddingModel\n",
    "from utils.embedding_models.providers import hugging_face\n",
    "from utils.embedding_models.providers import open_ai\n",
    "from utils.embedding_models.providers import supported_models\n",
    "from utils.embedding_models.schema import EmbeddingModel\n",
    "from utils.vectordb.vectordb import VectorDB, VectorIndex\n",
    "from tqdm.autonotebook import tqdm\n",
    "from time import sleep\n",
    "\n",
    "def wrapper(model: EmbeddingModel):\n",
    "    return CachedEmbeddingModel(model)\n",
    "\n",
    "embedding_models = {\n",
    "    \"HF_SDADAS\": hugging_face.init_model(model_info=supported_models.ST_POLISH_PARAPHRASE_FROM_DISTILROBERTA),\n",
    "    \"OPENAI_SMALL\": open_ai.init_model(api_key=open_ai_key, model_info=supported_models.TEXT_EMBEDDING_3_SMALL),\n",
    "    \"OPENAI_LARGE\": open_ai.init_model(api_key=open_ai_key, model_info=supported_models.TEXT_EMBEDDING_3_LARGE),\n",
    "    \"OPENAI__ADA\": open_ai.init_model(api_key=open_ai_key, model_info=supported_models.TEXT_EMBEDDING_ADA_002),\n",
    "}\n",
    "\n",
    "vector_db = VectorDB()\n",
    "for index_name, index in embedding_models.items():\n",
    "    vector_db.add_index(index_name, index)  \n",
    "\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "sections = pages_df['Section With Context'].values.tolist()\n",
    "for index_name in vector_db.list_indices():\n",
    "    cost_bar = tqdm(desc=f'{index_name}. Total cost ($)')\n",
    "    model = embedding_models[index_name]\n",
    "    for text in tqdm(sections, desc=f'{index_name}. Processed items'):\n",
    "        vector_db.insert_text(text, index_name)\n",
    "        cost_bar.update(model.get_total_cost() - cost_bar.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "test_df = pages_df.copy()[:400]\n",
    "\n",
    "for index_name in vector_db.list_indices():\n",
    "    model = embedding_models[index_name]\n",
    "    cost = model.get_total_cost()\n",
    "    embedding_tokens_bar = tqdm(desc=f\"{index_name}. Embedding cost ($): \")\n",
    "\n",
    "    identified_matches = []\n",
    "    for _, row in tqdm(list(test_df.iterrows()), desc=f\"{index_name}. Wiki sections: \"):\n",
    "        matched_with_answer = 0\n",
    "        for question in row['questions']:\n",
    "            found_text = vector_db.find_text(text=question, top_k=1, index_name=index_name)[0]\n",
    "\n",
    "            if found_text == row['Section With Context']:\n",
    "                matched_with_answer += 1\n",
    "            \n",
    "            embedding_tokens_bar.update(model.get_total_cost() - cost)\n",
    "        identified_matches.append(matched_with_answer)\n",
    "    test_df[index_name] = identified_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['HF_SDADAS'].mean(), test_df['HF_SDADAS'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['OPENAI_SMALL'].mean(), test_df['HF_SDADAS'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['OPENAI_LARGE'].mean(), test_df['HF_SDADAS'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['OPENAI__ADA'].mean(), test_df['HF_SDADAS'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_df.iloc[0]\n",
    "question_0 = sample['questions'][0]\n",
    "answer = sample['Section With Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_asnwers = vector_db.find_text(text=question_0, top_k=1, index_name='OPENAI_LARGE')\n",
    "found_asnwers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings-comparison-JqTXriCt-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
